{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gqcITDvt2mG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0cf63b-86bf-4863-85b2-2d3dcc4cc9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['User: Hi, can you tell me about Python?\\n', 'AI: Sure! Python is a popular programming language known for\\n', 'its readability.\\n', 'User: What can I use it for?\\n', 'AI: You can use Python for web development, data analysis,\\n', 'AI, and more.']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Thought Process\"\"\"\n",
        "\n",
        "\"\"\"I have a text file that contains conversation between a user and an AI chatbot.\n",
        "  Task 1.: My task is to separate the messages by speaker and AI.\"\"\"\n",
        "\n",
        "\"\"\"Step 1: load the text file that contains the conversation\n",
        "   Step 2: read the conversation and store them in a variable called lines\"\"\"\n",
        "\n",
        "path = '/content/chat.txt'\n",
        "with open(path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "print(lines)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" You can see output of the conversation here\"\"\"\n",
        "lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRkF_z5Y3VXI",
        "outputId": "252dd2ab-5cd8-4cb0-9f87-6b4fec6048b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['User: Hi, can you tell me about Python?\\n',\n",
              " 'AI: Sure! Python is a popular programming language known for\\n',\n",
              " 'its readability.\\n',\n",
              " 'User: What can I use it for?\\n',\n",
              " 'AI: You can use Python for web development, data analysis,\\n',\n",
              " 'AI, and more.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\"Step 3: Separate the User: and AI: part from the conversation and store the ID\n",
        "    of the speaker in a variable and the message in other variable using strip() function.\"\"\"\n",
        "\n",
        "\n",
        "exchanges = []\n",
        "for raw in lines:\n",
        "  raw = raw.strip()\n",
        "  if raw.startswith('User:'):\n",
        "    speaker, msg = 'User', raw[len('User:'):].strip()\n",
        "  elif raw.startswith('AI:'):\n",
        "    speaker, msg = 'AI', raw[len('AI:'):].strip()\n",
        "  else:\n",
        "    continue\n",
        "  exchanges.append((speaker, msg))"
      ],
      "metadata": {
        "id": "c9bwT8OZ3WnD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" You can see the parsed output of the conversation here\"\"\"\n",
        "exchanges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYkLdRlAGy1e",
        "outputId": "5d8e0e72-27b6-4a34-86f5-90f37f4fd3ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('User', 'Hi, can you tell me about Python?'),\n",
              " ('AI', 'Sure! Python is a popular programming language known for'),\n",
              " ('User', 'What can I use it for?'),\n",
              " ('AI', 'You can use Python for web development, data analysis,')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Task 2: Count total messages\"\"\"\n",
        "\n",
        "total = len(exchanges)\n",
        "user_count = 0\n",
        "for speaker, msg in exchanges:\n",
        "  if speaker == 'User':\n",
        "    user_count += 1\n",
        "ai_count = total - user_count\n",
        "\n",
        "print(f\"Total Messages: {total}\")\n",
        "print(f\"User Messages: {user_count}\")\n",
        "print(f\"AI Messages: {ai_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cQM0glE4Vpf",
        "outputId": "3dd17617-44da-4606-b576-f36e4e567cbc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Messages: 4\n",
            "User Messages: 2\n",
            "AI Messages: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Task 3: Keyword Analysis\n",
        "    Step 1: import nltk for keyword extraction\n",
        "    Step 2: use punkt_tab from nltk which will give us the split words from the texts\n",
        "    Step 3: use stopwords set to identify the common set of words in english and exclude them\n",
        "    step 4: get all the words excluding the common english words, use isalpha() for excluding punctuation mark\n",
        "    step 5: use counter to count the frequency of a word\"\"\"\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from collections import Counter\n",
        "all_msgs = []\n",
        "for _, msg in exchanges:\n",
        "  all_msgs.append(msg)\n",
        "words = []\n",
        "for msg in all_msgs:\n",
        "  #tokenize the word of the messages\n",
        "  tokens = word_tokenize(msg.lower())\n",
        "  for token in tokens:\n",
        "    if token.isalpha() and token.lower() not in stop_words:\n",
        "      words.append(token.lower())\n",
        "freq = Counter(words)\n",
        "top5 = freq.most_common(5)\n",
        "print(top5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfdOA6Yx4W7J",
        "outputId": "a6cf1c5e-1b1a-424d-abaa-960c96d8633b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('python', 3), ('use', 2), ('hi', 1), ('tell', 1), ('sure', 1)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Task 4: Generate the summary\"\"\"\n",
        "frq_w = []\n",
        "for m, _ in top5:\n",
        "  frq_w.append(m)\n",
        "summary = (\n",
        "    f\"Summary:\\n\"\n",
        "    f\"- The conversation had {total} exchanges.\\n\"\n",
        "    f\"- The user asked mainly about {' and '.join(frq_w[:2])}.\\n\"\n",
        "    f\"- Most common keywords: {', '.join(frq_w)}.\"\n",
        ")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvcdiNqE5_1R",
        "outputId": "13e9054a-dc4b-4d1d-bce8-867a80b9ab3e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "- The conversation had 4 exchanges.\n",
            "- The user asked mainly about python and use.\n",
            "- Most common keywords: python, use, hi, tell, sure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "li8UvMWA67KL"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}
